
---
title: "Exponential Simulation"
date: "April 13, 2015"
output:
  html_document:
    theme: cerulean
  pdf_document: default
  word_document: default
---


The following example make use of simulations to gather insight and investigate
the exponential probability distribution. This example simulates exponential
distribution and compares it to the Central Limit Theorem.  Random numbers are generated to study the theoretical mean and 
variance of the distribution.  We should expect both sample mean and variance 
to be close to the theoretical mean.  The complete R code for the simulation and results is given in the Appendix.


```{r,echo=FALSE,results='hide'}
# Class sim definition that stores the simulated data.
getEvent <- function(.Object) {return(.Object@event)}
getEvent2 <- function(.Object) {return(.Object@event2)}
setClass(
    Class = "sim", 
    slots = c(
        simName = "character", 
        event = "numeric",
        event2 = "numeric"
    ),
    prototype = prototype(
        simName = NA_character_,
        event = numeric(0)
    )
)
setGeneric(
    "randNum", function(.Object) {
        standardGeneric("randNum") }
)
setMethod("randNum",signature("sim"), getEvent)

```

```{r, echo=FALSE}
lambda <- 0.2       # rate parameters
sd <- 1/lambda      # standard deviations
n <- 40             # random sample size
reps <- 1000        # number of replications
nsamples <- 4       # number of iterations/plots
rows <- 1           # plot rows
cols <- 4           # plot columns
```


Applying `rexp` to study the exponential distribution we take n = 40 random exponentials and calculate the mean and variance of each of the samples. The mean and standard deviation (sd) of the exponential distribution is set to `1/lambda`.  For all simulations, lambda = 0.2.

### Sample Mean versus Theoretical Mean
When I analyze data, one of the first things I prefer to do is to look at the data in order to get a sense of the frequent values.  I explore the data by taking four samples as point estimates and generate four histograms which are used to view the shape of the data. The following histograms exhibit tails to the right and are said to be right skewed.  

```{r, echo=FALSE, fig.align='center',fig.height=2.8, fig.width=6.2}
set.seed(1)
simdata <- list()
par(mfrow = c(rows, cols))
for (i in seq(nsamples)) {
s1 <- new("sim",
           simName = "sim1", 
           event = rexp(n, rate = lambda))

simdata$mean[[i]] <- mean(getEvent(s1))
simdata$var[[i]] <- var(getEvent(s1))
#simdata$var <- var(simdata$mean[1:4])
hist(getEvent(s1), probability = TRUE, col = gray(.9), 
     main = "",
     xlab = paste("Sim", i)
     )
rug(jitter(getEvent(s1)), col = "purple")
s = seq(0, 35, 0.4)
pdf = dexp(s, lambda)
lines(s, pdf)
}
# simdata
```

Figure 1: The mean for each figure is shown below.  Since the samples are random, each has its own mean and variance.  These sample means approximate `1/lambda`.  As recognized, the mean is a  frequent way to view the distribution center.

```{r, echo=FALSE}
simdata
```

I use the replicate function and repeat the calculation 1000 times and take the mean and variance of this distribution.  The commands were ran four times and plotted with histograms.
```{r, echo=FALSE,fig.align='center',fig.height=2.8, fig.width=6.2}
set.seed(1)
distdata <- list()
par(mfrow = c(rows, cols))
for (i in seq(nsamples)) { # 
    # Distribution of sample means and variance.
    m40.1 <- new("sim",
                 simName = "sim1",
                 event = replicate(reps, mean(rexp(n, rate = lambda))))
    #str(getEvent(m40.1))
    distdata$mean[[i]] <- getEvent(m40.1)
    distdata$var[[i]] <- var(getEvent(m40.1))
    distdata$sd[[i]] <- sd(getEvent(m40.1))  
    hist(getEvent(m40.1),
         probability = TRUE,
         col = gray(.9),
         main = "",
         xlab = paste("Sim", i)
         )
}
# Get mean of fourth list of means.
# mean(unlist(distdata[["mean"]][1]))
```
Figure 2: After repeating the calculation 1000 times, the means approximate `1/lambda`.  Also the shape of the distribution resembles the shape of a normal, symmetrical distribution, centered around `1/lambda`, which is considered to be the true average. 


The follow calculations list the means for Figure 2.
```{r, echo=FALSE,eval=TRUE}
for(i in 1:length(distdata[["mean"]])) {
print(mean(unlist(distdata[["mean"]][i])))
}
```

### Sample Variance versus Theoretical Variance

When we look at data variability, two measurements are used, variance and standard deviation.  Standard deviation illustrates how far an element is from the mean.  When the deviations are squared and averaged, then the result is equivalent to the sample variance.  The sample variances approximates the theoretical variance.  Also, the sampling distribution indicates a degree of variability.

```{r, echo=FALSE}
# Using the point data as a reference we compare the variance of the distribution that was replicated 1000 times.
# simdata$var
```
```{r}
# Variance of Figure 2 four sample calculations repeated 1000 times.
unlist(distdata[["var"]][1:4])
# Theoretical variance calculation.
((sd)/sqrt(n))^2
```

```{r, echo=FALSE,fig.align='center',fig.height=4.3, fig.width=4.3}
# When we use a larger sample size and repeat the calculations 1000 times the variance approaches the theoretical variance.

n <- 400     # random sample size
rep <- 10000 # replication number size

# Distributions are approaching theroretical mean as n is increased.
cL <- new("sim",
          simName = "sim1", 
          event = runif(10),
          event2 = replicate(rep, mean(rexp(n, rate = lambda))))
#getEvent2(cL)
#var(getEvent2(cL))
```

### Show that the distribution is approximately normal
  
A normal distribution model follows a certain mode, identified as symmetric and unimodal. Unimodal is defined as a distribution that has one easily seen peak, commonly known as a bell-shaped curve.  Nevertheless, the curve may differ as determined by the mean and standard deviation.

Figure 3: Illustrates an increase of sample size and number of replications by a factor of 10.  The sample size and replication were increased in order to get a clearer picture of a normal distribution.  The distribution is centered around a mean of `1/lambda`.  It makes sense as the sample size increases the distribution resembles the population mean. 

```{r, echo=FALSE,fig.align='center',fig.height=3, fig.width=3}
hist(getEvent2(cL),
      breaks = 60,
      col = gray(.9),
      main = "Exponential lambda",
      xlab = "Means"
      )
```

According to the [Central Limit Theorem](http://en.wikipedia.org/wiki/Central_limit_theorem) the distribution of the mean is approximately normal.  The approximation improves as the sample size increases.  Therefore, if the number of samples are large enough the average is approximately normal with mean `1/lambda` and standard deviation of `1/lambda`. The approximation can be poor if the sample size is small, but it improves with larger sample sizes.
    
## Appendix
Set distribution and graph parameters.
```{r, echo=TRUE}
lambda <- 0.2       # rate parameters
n <- 40             # random sample size
reps <- 1000        # number of replications
nsamples <- 4       # number of samples 
rows <- 2           # plot rows
cols <- 2           # plot columns
```
Convenient simulation class definition
```{r, eval=FALSE,echo=TRUE, message=FALSE}
# Class sim definition that stores the simulated data.
getEvent <- function(.Object) {return(.Object@event)}
getEvent2 <- function(.Object) {return(.Object@event2)}
setClass(
    Class = "sim", 
    slots = c(
        simName = "character", 
        event = "numeric",
        event2 = "numeric"
    ),
    prototype = prototype(
        simName = NA_character_,
        event = numeric(0)
    )
)
setGeneric(
    "randNum", function(.Object) {
        standardGeneric("randNum") }
)
setMethod("randNum",signature("sim"), getEvent)
```
```{r, eval=FALSE, echo=TRUE, fig.align='left',fig.height=4, fig.width=4}
# Plot figure 1 and mean and variance calculations.
set.seed(1)
simdata <- list()
par(mfrow = c(rows, cols), mar = rep(3, 4))
for (i in seq(nsamples)) {
s1 <- new("sim",
           simName = "sim1", 
           event = rexp(n, rate = lambda))

simdata$mean[[i]] <- mean(getEvent(s1))
simdata$var[[i]] <- var(getEvent(s1))
hist(getEvent(s1), probability = TRUE, col = gray(.9), 
     main = "Exponential lambda",
     xlab = paste("Sim", i)
     )
rug(jitter(getEvent(s1)), col = "purple")
s = seq(0, 35, 0.4)
pdf = dexp(s, lambda)
lines(s, pdf)
}
simdata
```

```{r, eval=FALSE, echo=TRUE,fig.align='center',fig.height=4, fig.width=4}
# Plot figure 2 and calculate means.
set.seed(1)
distdata <- list()
par(mfrow = c(rows, cols))
for (i in seq(nsamples)) { # 
    # Distribution of sample means and variance.
    m40.1 <- new("sim",
                 simName = "sim1",
                 event = replicate(reps, mean(rexp(n, rate = lambda))))
    #str(getEvent(m40.1))
    distdata$mean[[i]] <- getEvent(m40.1)
    distdata$var[[i]] <- var(getEvent(m40.1))
    distdata$sd[[i]] <- sd(getEvent(m40.1))  
    hist(getEvent(m40.1),
         probability = TRUE,
         col = gray(.9),
         main = "Exponential lambda",
         xlab = paste("Sim", i)
         )
}
# Get mean of fourth list of means.
# mean(unlist(distdata[["mean"]][1]))
for(i in 1:length(distdata[["mean"]])) {
print(mean(unlist(distdata[["mean"]][i])))
}
```
```{r eval=FALSE, echo=TRUE}
# Variance of Figure 2 four sample calculations repeated 1000 times.
unlist(distdata[["var"]][1:4])
# Theoretical variance calculation.
((sd)/sqrt(n))^2
```

```{r, eval=FALSE, echo=TRUE,fig.align='center',fig.height=4, fig.width=4}
# Plot figure 3 and calculate mean.
n <- 400     # random sample size
rep <- 10000 # replication number size

# Distribution are approaching theroretical mean as n is increased.
cL <- new("sim",
          simName = "sim1", 
          event2 = replicate(rep, mean(rexp(n, rate = lambda))))
#getEvent2(cL)
var(getEvent2(cL))
```

